{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make lookup table from whole raw data\n",
    "-----\n",
    "・use pubchempy and CASRN, get need property from PubChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_parent_dir = os.path.dirname(os.path.dirname(current_dir))\n",
    "src_dir = os.path.join(parent_parent_dir, 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "import collections\n",
    "import sqlite3\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pubchempy as pcp\n",
    "from prep import for_lookup, for_lookup_val, prep_pubchem_bycas\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem, Descriptors, rdMolDescriptors\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import robust_scale\n",
    "from tqdm import tqdm\n",
    "from util import file_checker, pickle_dump, pickle_load, robust_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not done yet!\n"
     ]
    }
   ],
   "source": [
    "if file_checker(\"../../data/processed/other/all_pubchem_data.tsv\", False):\n",
    "    print(\"not done yet!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pubchempy for gathering data (canonical smiles, xlogp, and TPSA) for GA\n",
    "# before using pubchempy, gather all CAS-RN in all data \n",
    "\n",
    "cas = []\n",
    "for test_num in [\"0901\", \"0902\", \"0904\", \"0905\"]:\n",
    "    for lig in [\"ago\", \"anta\"]:\n",
    "        for file_name in [\"for_GA\", \"validation\"]:\n",
    "            df = pd.read_csv(f\"../../data/processed/{test_num}_{lig}/{file_name}.tsv\", sep=\"\\t\", header=None)\n",
    "            df = df.dropna()\n",
    "            for i in range(len(df)):\n",
    "                cas.append(df.iloc[i,0])\n",
    "\n",
    "for test_num in [\"0701\", \"0702\", \"0907\", \"1001\", \"1002\"]:\n",
    "    for file_name in [\"for_GA\", \"validation\"]:\n",
    "        df = pd.read_csv(f\"../../data/processed/{test_num}/{file_name}.tsv\", sep=\"\\t\", header=None)\n",
    "        df = df.dropna()\n",
    "        for i in range(len(df)):\n",
    "            cas.append(df.iloc[i,0])\n",
    "\n",
    "cas = list(set(cas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14625/14625 [10:50:36<00:00,  2.67s/it] \n"
     ]
    }
   ],
   "source": [
    "property = ['CanonicalSMILES', 'XLogP', 'TPSA']\n",
    "all_data = prep_pubchem_bycas(cas, property)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_na = all_data[0].dropna()\n",
    "all_data_na.to_csv(\"../../data/processed/other/all_pubchem_data.tsv\", sep=\"\\t\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error means all CASRN that cannot get full data from pubchem\n",
    "error = set(all_data[1]) | set(cas)\n",
    "pickle_dump(error, \"../../data/processed/other/all_pubchem_error.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11422/11422 [00:03<00:00, 2948.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# select pubchem data if a CASRN has multiple CIDs\n",
    "all_data_na = all_data_na.reset_index()\n",
    "all_data_na = all_data_na.drop(columns=[\"index\"])\n",
    "\n",
    "all_data_dict = dict()\n",
    "for i in tqdm(range(len(all_data_na))):\n",
    "    cas = all_data_na[\"CAS\"][i]\n",
    "    if cas not in all_data_dict.keys():\n",
    "        all_data_dict[cas] = []\n",
    "        for n in range(len(all_data_na.iloc[i])):\n",
    "            all_data_dict[cas].append(all_data_na.iloc[i,n])\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(all_data_dict, orient='index', columns=[\"CID\",\"CAS\",\"CanonicalSmiles\",\"xlogp\",\"tpsa\"]).reset_index().drop(columns=[\"index\"])\n",
    "df.to_csv(\"../../data/processed/other/all_pubchem_data.tsv\",sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11422/11422 [09:33<00:00, 19.93it/s] \n",
      "100%|██████████| 11422/11422 [38:04<00:00,  5.00it/s] \n"
     ]
    }
   ],
   "source": [
    "lookup_whole = for_lookup(all_data_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dump(lookup_whole, \"../../data/processed/other/lookup_whole.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6737/6737 [04:22<00:00, 25.71it/s] \n",
      "100%|██████████| 6737/6737 [12:39<00:00,  8.87it/s] \n",
      "100%|██████████| 6753/6753 [03:33<00:00, 31.64it/s] \n",
      "100%|██████████| 6753/6753 [13:23<00:00,  8.41it/s] \n",
      "100%|██████████| 6724/6724 [03:31<00:00, 31.79it/s] \n",
      "100%|██████████| 6724/6724 [13:29<00:00,  8.31it/s] \n",
      "100%|██████████| 6760/6760 [03:35<00:00, 31.44it/s] \n",
      "100%|██████████| 6760/6760 [14:33<00:00,  7.74it/s]  \n",
      "100%|██████████| 6772/6772 [03:24<00:00, 33.08it/s] \n",
      "100%|██████████| 6772/6772 [14:14<00:00,  7.93it/s]  \n",
      "100%|██████████| 6770/6770 [03:15<00:00, 34.68it/s] \n",
      "100%|██████████| 6770/6770 [14:15<00:00,  7.92it/s]  \n",
      "100%|██████████| 6766/6766 [03:19<00:00, 33.98it/s] \n",
      "100%|██████████| 6766/6766 [22:15<00:00,  5.07it/s]  \n",
      "100%|██████████| 6768/6768 [05:47<00:00, 19.49it/s] \n",
      "100%|██████████| 6768/6768 [22:33<00:00,  5.00it/s]  \n",
      "100%|██████████| 7040/7040 [06:19<00:00, 18.55it/s] \n",
      "100%|██████████| 7040/7040 [24:20<00:00,  4.82it/s]  \n",
      "100%|██████████| 7043/7043 [03:32<00:00, 33.11it/s] \n",
      "100%|██████████| 7043/7043 [15:08<00:00,  7.75it/s] \n",
      "100%|██████████| 6756/6756 [03:19<00:00, 33.80it/s] \n",
      "100%|██████████| 6756/6756 [14:35<00:00,  7.72it/s] \n",
      "100%|██████████| 438/438 [00:00<00:00, 594.61it/s]\n",
      "100%|██████████| 438/438 [00:02<00:00, 162.94it/s]\n",
      "100%|██████████| 435/435 [00:00<00:00, 551.14it/s]\n",
      "100%|██████████| 435/435 [00:02<00:00, 166.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# make for_GA dataset \n",
    "for test_num in [\"0901\", \"0902\", \"0904\", \"0905\"]:\n",
    "    for lig in [\"ago\", \"anta\"]:\n",
    "        for file_name in [\"for_GA\"]:\n",
    "            df = pd.read_csv(f\"../../data/processed/{test_num}_{lig}/{file_name}.tsv\", sep=\"\\t\", header=None)\n",
    "            df = df.dropna()\n",
    "            cas = []\n",
    "            for i in range(len(df)):\n",
    "                cas.append(df.iloc[i,0])\n",
    "            use_data = all_data_na[all_data_na[\"CAS\"].isin(cas)].reset_index().drop(columns=[\"index\"])\n",
    "            lookup = for_lookup(use_data)\n",
    "            pickle_dump(lookup, f\"../../data/processed/{test_num}_{lig}/{file_name}_lookup.pickle\")\n",
    "\n",
    "for test_num in [\"0701\", \"0702\", \"0907\", \"1001\", \"1002\"]:\n",
    "    for file_name in [\"for_GA\"]:\n",
    "        df = pd.read_csv(f\"../../data/processed/{test_num}/{file_name}.tsv\", sep=\"\\t\", header=None)\n",
    "        df = df.dropna()\n",
    "        cas = []\n",
    "        for i in range(len(df)):\n",
    "            cas.append(df.iloc[i,0])\n",
    "        use_data = all_data_na[all_data_na[\"CAS\"].isin(cas)].reset_index().drop(columns=[\"index\"])\n",
    "        lookup = for_lookup(use_data)\n",
    "        pickle_dump(lookup, f\"../../data/processed/{test_num}/{file_name}_lookup.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if compound in validation dataset cannot make lookup, collect data from text in JACVAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0901 ago {'50-41-9'}\n",
      "0901 anta {'82640-04-8'}\n",
      "0902 ago {'50-41-9', '57-30-7', '1461-22-9'}\n",
      "0902 anta {'82640-04-8', '50-41-9'}\n",
      "0904 ago set()\n",
      "0904 anta set()\n",
      "0905 ago set()\n",
      "0905 anta set()\n",
      "0701 {'10108-64-2', '1910-42-5', '7789-12-0', '76-87-9', '554-13-2', '549-18-8', '318-98-9', '151-50-8', '7446-18-6', '7758-99-8', '152-11-4', '13410-01-0', '1330-20-7', '73791-47-6', '51-42-3', '10043-35-3', '7784-46-5', '7647-14-5', '614-39-1', '7487-94-7', '8007-59-8', '7447-40-7', '62-76-0', '7681-49-4', '1327-53-3'}\n",
      "0702 {'107-64-2', '7758-98-7', '866-84-2', '25646-77-9', '10361-37-2', '9005-64-5', '3926-62-3', '68515-48-0', '557-05-1', '1314-13-2', '7778-80-5', '917-61-3', '12125-02-9', '7779-90-0'}\n",
      "0907 {'84852-15-3', '2943-75-1'}\n",
      "1001 {'82385-42-0', '147-24-0', '69-57-8', '115-09-3', '10043-35-3', '54-21-7', '7447-41-8'}\n",
      "1002 {'147-24-0', '10043-35-3', '34381-68-5'}\n"
     ]
    }
   ],
   "source": [
    "correct_cas = set(all_data_na[\"CAS\"])\n",
    "\n",
    "all_val_error_cas = set()\n",
    "for test_num in [\"0901\", \"0902\", \"0904\", \"0905\"]:\n",
    "    for lig in [\"ago\", \"anta\"]:\n",
    "        val = pd.read_csv(f\"../../data/processed/{test_num}_{lig}/validation.tsv\", sep=\"\\t\", header=None)\n",
    "        val_cas = set(val.iloc[:,0])\n",
    "        val_error_cas = val_cas - correct_cas\n",
    "        all_val_error_cas = all_val_error_cas | val_error_cas\n",
    "        print(test_num, lig, val_error_cas)\n",
    "\n",
    "for test_num in [\"0701\", \"0702\", \"0907\", \"1001\", \"1002\"]:\n",
    "    val = pd.read_csv(f\"../../data/processed/{test_num}/validation.tsv\", sep=\"\\t\", header=None)\n",
    "    val_cas = set(val.iloc[:,0])\n",
    "    val_error_cas = val_cas - correct_cas\n",
    "    all_val_error_cas = all_val_error_cas | val_error_cas\n",
    "    print(test_num, val_error_cas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make cas and severity data only in whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_num in [\"0901\", \"0902\", \"0904\", \"0905\"]:\n",
    "    for lig in [\"ago\", \"anta\"]:\n",
    "        file_name = \"for_GA\"\n",
    "        df = pd.read_csv(f\"../../data/processed/{test_num}_{lig}/{file_name}.tsv\", sep=\"\\t\", header=None)\n",
    "        df = df.dropna()\n",
    "        cas = []\n",
    "        for i in range(len(df)):\n",
    "            cas.append(df.iloc[i,0])\n",
    "        use_cas =  set(all_data_na[all_data_na[\"CAS\"].isin(cas)].reset_index().drop(columns=[\"index\"])[\"CAS\"])\n",
    "        test_name = test_num + \"_\" + lig\n",
    "        cas_tox = pd.read_csv(f\"../../data/processed/{test_name}/cas_sev.tsv\", sep=\"\\t\", header=None)\n",
    "        cas_tox_use = []\n",
    "        for i in range(len(cas_tox)):\n",
    "            if cas_tox.iloc[i,0] in use_cas:\n",
    "                cas_tox_use.append([cas_tox.iloc[i,0], cas_tox.iloc[i,1]])\n",
    "        pd.DataFrame(cas_tox_use).to_csv(f\"../../data/processed/{test_name}/cas_sev_use.tsv\", sep=\"\\t\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cas =  set(all_data_na[all_data_na[\"CAS\"].isin(cas)].reset_index().drop(columns=[\"index\"])[\"CAS\"])\n",
    "for test_num in [\"0701\", \"0702\", \"0907\", \"1001\", \"1002\"]:\n",
    "    file_name = \"for_GA\"\n",
    "    test_name = test_num\n",
    "    df = pd.read_csv(f\"../../data/processed/{test_num}/{file_name}.tsv\", sep=\"\\t\", header=None)\n",
    "    df = df.dropna()\n",
    "    cas = []\n",
    "    for i in range(len(df)):\n",
    "        cas.append(df.iloc[i,0])\n",
    "    use_cas =  set(all_data_na[all_data_na[\"CAS\"].isin(cas)].reset_index().drop(columns=[\"index\"])[\"CAS\"])\n",
    "    cas_tox = pd.read_csv(f\"../../data/processed/{test_name}/cas_sev.tsv\", sep=\"\\t\", header=None)\n",
    "    cas_tox_use = []\n",
    "    for i in range(len(cas_tox)):\n",
    "        if cas_tox.iloc[i,0] in use_cas:\n",
    "            cas_tox_use.append([cas_tox.iloc[i,0], cas_tox.iloc[i,1]])\n",
    "    pd.DataFrame(cas_tox_use).to_csv(f\"../../data/processed/{test_name}/cas_sev_use.tsv\", sep=\"\\t\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/processed/other/all_pubchem_data.tsv\", sep=\"\\t\")\n",
    "df_dict = dict(zip(df.iloc[:,1], df.iloc[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_num in [\"0701\", \"0702\", \"0907\", \"1001\", \"1002\"]:\n",
    "    test_name = test_num\n",
    "    cas_tox_use = pd.read_csv(f\"../../data/processed/{test_name}/cas_sev_use.tsv\", sep=\"\\t\", header=None)\n",
    "    smiles = [df_dict.get(cas, None) for cas in cas_tox_use.iloc[:, 0]]\n",
    "    cas_tox_use.loc[:,3] = smiles\n",
    "    pd.DataFrame(cas_tox_use).to_csv(f\"../../data/processed/{test_name}/cas_sev_use.tsv\", sep=\"\\t\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_num in [\"0901\", \"0902\", \"0904\", \"0905\"]:\n",
    "    for lig in [\"ago\", \"anta\"]:\n",
    "        test_name = test_num + \"_\" + lig\n",
    "        cas_tox_use = pd.read_csv(f\"../../data/processed/{test_name}/cas_sev_use.tsv\", sep=\"\\t\", header=None)\n",
    "        smiles = [df_dict.get(cas, None) for cas in cas_tox_use.iloc[:, 0]]\n",
    "        cas_tox_use.loc[:,3] = smiles\n",
    "        pd.DataFrame(cas_tox_use).to_csv(f\"../../data/processed/{test_name}/cas_sev_use.tsv\", sep=\"\\t\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get data about CAS-RN written below from PubChem or RDkit\n",
    "  \n",
    "0701 8007-59-8 (cas = 7681-52-9, xlogp is from rdkit)   \n",
    "0701 1327-53-3 (cas = CAS-1327-53-3, xlogp is from rdkit)   \n",
    "0701 1330-20-7 (cas = CAS-1330-20-7, xlogp is from rdkit)  \n",
    "0702 68515-48-0 (cas = CAS-68515-48-0, xlogp is from rdkit)  \n",
    "0702 9005-64-5 (cas = 1052273-76-3, xlogp is from rdkit)  \n",
    "0907 84852-15-3 (cas = CAS-84852-15-3, xlogp is from rdkit)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:02<00:00, 16.17it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00,  9.63it/s]\n",
      "100%|██████████| 86/86 [00:07<00:00, 10.97it/s]\n",
      "100%|██████████| 21/21 [00:05<00:00,  4.02it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 2734.23it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 2735.12it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 2871.56it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 2775.85it/s]\n",
      "100%|██████████| 72/72 [01:06<00:00,  1.08it/s]\n",
      "100%|██████████| 56/56 [00:37<00:00,  1.50it/s]\n",
      "100%|██████████| 26/26 [00:05<00:00,  4.70it/s]\n",
      "100%|██████████| 18/18 [00:19<00:00,  1.07s/it]\n",
      "100%|██████████| 16/16 [00:08<00:00,  1.91it/s]\n"
     ]
    }
   ],
   "source": [
    "property = ['CanonicalSMILES', 'XLogP', 'TPSA']\n",
    "\n",
    "for test_num in [\"0901\", \"0902\", \"0904\", \"0905\"]:\n",
    "    for lig in [\"ago\", \"anta\"]:\n",
    "        val = pd.read_csv(f\"../../data/processed/{test_num}_{lig}/validation.tsv\", sep=\"\\t\", header=None)\n",
    "        tsv = []\n",
    "        for i in tqdm(range(len(val))):\n",
    "            if val.iloc[i,0] in all_val_error_cas:\n",
    "                time.sleep(2)\n",
    "                data = pcp.get_properties(property, val.iloc[i,0], \"name\", as_dataframe=True)\n",
    "                data = data.reset_index()\n",
    "                col = []\n",
    "                col.append(val.iloc[i,0])\n",
    "                col.append(val.iloc[i,1])\n",
    "                try:\n",
    "                    col.append(data[\"CanonicalSMILES\"][0])\n",
    "                    smiles = data[\"CanonicalSMILES\"][0]\n",
    "                except:\n",
    "                    col.append(\"###\")\n",
    "                    smiles = \"###\"\n",
    "                try:\n",
    "                    col.append(data[\"XLogP\"][0])\n",
    "                except:\n",
    "                    if smiles == \"###\":\n",
    "                        col.append(\"###\")\n",
    "                    else:\n",
    "                        mol = Chem.MolFromSmiles(smiles)\n",
    "                        col.append(Descriptors.MolLogP(mol))\n",
    "                try:\n",
    "                    col.append(data[\"TPSA\"][0])\n",
    "                except:\n",
    "                    if smiles == \"###\":\n",
    "                        col.append(\"###\")\n",
    "                    else:\n",
    "                        mol = Chem.MolFromSmiles(smiles)\n",
    "                        col.append(rdMolDescriptors.CalcTPSA(mol))\n",
    "                if \"###\" in col:\n",
    "                    print(test_num, val.iloc[i,0])\n",
    "                tsv.append(col)\n",
    "            else:\n",
    "                col = []\n",
    "                col.append(val.iloc[i,0])\n",
    "                col.append(val.iloc[i,1])\n",
    "                for n in range(2, len(all_data_dict[val.iloc[i,0]])):\n",
    "                    col.append(all_data_dict[val.iloc[i,0]][n])\n",
    "                tsv.append(col)\n",
    "        pd.DataFrame(tsv).to_csv(f\"../../data/processed/{test_num}_{lig}/validation_pubchem.tsv\", sep=\"\\t\", header=None, index=False)\n",
    "\n",
    "        if len(tsv) != len(val):\n",
    "            cas = [row[0] for row in tsv]\n",
    "            print(set(val[0]) - set(cas))\n",
    "\n",
    "for test_num in [\"0701\", \"0702\", \"0907\", \"1001\", \"1002\"]:\n",
    "    val = pd.read_csv(f\"../../data/processed/{test_num}/validation.tsv\", sep=\"\\t\", header=None)\n",
    "    tsv = []\n",
    "    for i in tqdm(range(len(val))):\n",
    "        if val.iloc[i,0] == \"8007-59-8\":\n",
    "            val.iloc[i,0] = \"7681-52-9\"\n",
    "            time.sleep(2)\n",
    "            data = pcp.get_properties(property, val.iloc[i,0], \"name\", as_dataframe=True)\n",
    "            data = data.reset_index()\n",
    "            col = []\n",
    "            col.append(val.iloc[i,0])\n",
    "            col.append(val.iloc[i,1])\n",
    "            try:\n",
    "                col.append(data[\"CanonicalSMILES\"][0])\n",
    "                smiles = data[\"CanonicalSMILES\"][0]\n",
    "            except:\n",
    "                col.append(\"###\")\n",
    "                smiles = \"###\"\n",
    "            try:\n",
    "                col.append(data[\"XLogP\"][0])\n",
    "            except:\n",
    "                if smiles == \"###\":\n",
    "                    col.append(\"###\")\n",
    "                else:\n",
    "                    mol = Chem.MolFromSmiles(smiles)\n",
    "                    col.append(Descriptors.MolLogP(mol))\n",
    "            try:\n",
    "                col.append(data[\"TPSA\"][0])\n",
    "            except:\n",
    "                if smiles == \"###\":\n",
    "                    col.append(\"###\")\n",
    "                else:\n",
    "                    mol = Chem.MolFromSmiles(smiles)\n",
    "                    col.append(rdMolDescriptors.CalcTPSA(mol))\n",
    "            if \"###\" in col:\n",
    "                print(test_num, val.iloc[i,0])\n",
    "            tsv.append(col)\n",
    "        elif val.iloc[i,0] == \"1327-53-3\":\n",
    "            val.iloc[i,0] = \"CAS-1327-53-3\"\n",
    "            time.sleep(2)\n",
    "            data = pcp.get_properties(property, val.iloc[i,0], \"name\", as_dataframe=True)\n",
    "            data = data.reset_index()\n",
    "            col = []\n",
    "            col.append(val.iloc[i,0])\n",
    "            col.append(val.iloc[i,1])\n",
    "            try:\n",
    "                col.append(data[\"CanonicalSMILES\"][0])\n",
    "                smiles = data[\"CanonicalSMILES\"][0]\n",
    "            except:\n",
    "                col.append(\"###\")\n",
    "                smiles = \"###\"\n",
    "            try:\n",
    "                col.append(data[\"XLogP\"][0])\n",
    "            except:\n",
    "                if smiles == \"###\":\n",
    "                    col.append(\"###\")\n",
    "                else:\n",
    "                    mol = Chem.MolFromSmiles(smiles)\n",
    "                    col.append(Descriptors.MolLogP(mol))\n",
    "            try:\n",
    "                col.append(data[\"TPSA\"][0])\n",
    "            except:\n",
    "                if smiles == \"###\":\n",
    "                    col.append(\"###\")\n",
    "                else:\n",
    "                    mol = Chem.MolFromSmiles(smiles)\n",
    "                    col.append(rdMolDescriptors.CalcTPSA(mol))\n",
    "            if \"###\" in col:\n",
    "                print(test_num, val.iloc[i,0])\n",
    "            tsv.append(col)\n",
    "        elif val.iloc[i,0] == \"1330-20-7\":\n",
    "            val.iloc[i,0] =  \"CAS-1330-20-7\"\n",
    "            time.sleep(2)\n",
    "            data = pcp.get_properties(property, val.iloc[i,0], \"name\", as_dataframe=True)\n",
    "            data = data.reset_index()\n",
    "            col = []\n",
    "            col.append(val.iloc[i,0])\n",
    "            col.append(val.iloc[i,1])\n",
    "            try:\n",
    "                col.append(data[\"CanonicalSMILES\"][0])\n",
    "                smiles = data[\"CanonicalSMILES\"][0]\n",
    "            except:\n",
    "                col.append(\"###\")\n",
    "                smiles = \"###\"\n",
    "            try:\n",
    "                col.append(data[\"XLogP\"][0])\n",
    "            except:\n",
    "                if smiles == \"###\":\n",
    "                    col.append(\"###\")\n",
    "                else:\n",
    "                    mol = Chem.MolFromSmiles(smiles)\n",
    "                    col.append(Descriptors.MolLogP(mol))\n",
    "            try:\n",
    "                col.append(data[\"TPSA\"][0])\n",
    "            except:\n",
    "                if smiles == \"###\":\n",
    "                    col.append(\"###\")\n",
    "                else:\n",
    "                    mol = Chem.MolFromSmiles(smiles)\n",
    "                    col.append(rdMolDescriptors.CalcTPSA(mol))\n",
    "            if \"###\" in col:\n",
    "                print(test_num, val.iloc[i,0])\n",
    "            tsv.append(col)\n",
    "        elif val.iloc[i,0] == \"68515-48-0\":\n",
    "            val.iloc[i,0] = \"CAS-68515-48-0\"\n",
    "            time.sleep(2)\n",
    "            data = pcp.get_properties(property, val.iloc[i,0], \"name\", as_dataframe=True)\n",
    "            data = data.reset_index()\n",
    "            col = []\n",
    "            col.append(val.iloc[i,0])\n",
    "            col.append(val.iloc[i,1])\n",
    "            try:\n",
    "                col.append(data[\"CanonicalSMILES\"][0])\n",
    "                smiles = data[\"CanonicalSMILES\"][0]\n",
    "            except:\n",
    "                col.append(\"###\")\n",
    "                smiles = \"###\"\n",
    "            try:\n",
    "                col.append(data[\"XLogP\"][0])\n",
    "            except:\n",
    "                if smiles == \"###\":\n",
    "                    col.append(\"###\")\n",
    "                else:\n",
    "                    mol = Chem.MolFromSmiles(smiles)\n",
    "                    col.append(Descriptors.MolLogP(mol))\n",
    "            try:\n",
    "                col.append(data[\"TPSA\"][0])\n",
    "            except:\n",
    "                if smiles == \"###\":\n",
    "                    col.append(\"###\")\n",
    "                else:\n",
    "                    mol = Chem.MolFromSmiles(smiles)\n",
    "                    col.append(rdMolDescriptors.CalcTPSA(mol))\n",
    "            if \"###\" in col:\n",
    "                print(test_num, val.iloc[i,0])\n",
    "            tsv.append(col)\n",
    "        elif val.iloc[i,0] == \"9005-64-5\":\n",
    "            val.iloc[i,0] = \"1052273-76-3\"\n",
    "            time.sleep(2)\n",
    "            data = pcp.get_properties(property, val.iloc[i,0], \"name\", as_dataframe=True)\n",
    "            data = data.reset_index()\n",
    "            col = []\n",
    "            col.append(val.iloc[i,0])\n",
    "            col.append(val.iloc[i,1])\n",
    "            try:\n",
    "                col.append(data[\"CanonicalSMILES\"][0])\n",
    "                smiles = data[\"CanonicalSMILES\"][0]\n",
    "            except:\n",
    "                col.append(\"###\")\n",
    "                smiles = \"###\"\n",
    "            try:\n",
    "                col.append(data[\"XLogP\"][0])\n",
    "            except:\n",
    "                if smiles == \"###\":\n",
    "                    col.append(\"###\")\n",
    "                else:\n",
    "                    mol = Chem.MolFromSmiles(smiles)\n",
    "                    col.append(Descriptors.MolLogP(mol))\n",
    "            try:\n",
    "                col.append(data[\"TPSA\"][0])\n",
    "            except:\n",
    "                if smiles == \"###\":\n",
    "                    col.append(\"###\")\n",
    "                else:\n",
    "                    mol = Chem.MolFromSmiles(smiles)\n",
    "                    col.append(rdMolDescriptors.CalcTPSA(mol))\n",
    "            if \"###\" in col:\n",
    "                print(test_num, val.iloc[i,0])\n",
    "            tsv.append(col)\n",
    "        elif val.iloc[i,0] == \"84852-15-3\":\n",
    "            val.iloc[i,0]  = \"CAS-84852-15-3\"\n",
    "            time.sleep(2)\n",
    "            data = pcp.get_properties(property, val.iloc[i,0], \"name\", as_dataframe=True)\n",
    "            data = data.reset_index()\n",
    "            col = []\n",
    "            col.append(val.iloc[i,0])\n",
    "            col.append(val.iloc[i,1])\n",
    "            try:\n",
    "                col.append(data[\"CanonicalSMILES\"][0])\n",
    "                smiles = data[\"CanonicalSMILES\"][0]\n",
    "            except:\n",
    "                col.append(\"###\")\n",
    "                smiles = \"###\"\n",
    "            try:\n",
    "                col.append(data[\"XLogP\"][0])\n",
    "            except:\n",
    "                if smiles == \"###\":\n",
    "                    col.append(\"###\")\n",
    "                else:\n",
    "                    mol = Chem.MolFromSmiles(smiles)\n",
    "                    col.append(Descriptors.MolLogP(mol))\n",
    "            try:\n",
    "                col.append(data[\"TPSA\"][0])\n",
    "            except:\n",
    "                if smiles == \"###\":\n",
    "                    col.append(\"###\")\n",
    "                else:\n",
    "                    mol = Chem.MolFromSmiles(smiles)\n",
    "                    col.append(rdMolDescriptors.CalcTPSA(mol))\n",
    "            if \"###\" in col:\n",
    "                print(test_num, val.iloc[i,0])\n",
    "            tsv.append(col)\n",
    "        elif val.iloc[i,0] in all_val_error_cas:\n",
    "            time.sleep(2)\n",
    "            data = pcp.get_properties(property, val.iloc[i,0], \"name\", as_dataframe=True)\n",
    "            data = data.reset_index()\n",
    "            col = []\n",
    "            col.append(val.iloc[i,0])\n",
    "            col.append(val.iloc[i,1])\n",
    "            try:\n",
    "                col.append(data[\"CanonicalSMILES\"][0])\n",
    "                smiles = data[\"CanonicalSMILES\"][0]\n",
    "            except:\n",
    "                col.append(\"###\")\n",
    "                smiles = \"###\"\n",
    "            try:\n",
    "                col.append(data[\"XLogP\"][0])\n",
    "            except:\n",
    "                if smiles == \"###\":\n",
    "                    col.append(\"###\")\n",
    "                else:\n",
    "                    mol = Chem.MolFromSmiles(smiles)\n",
    "                    col.append(Descriptors.MolLogP(mol))\n",
    "            try:\n",
    "                col.append(data[\"TPSA\"][0])\n",
    "            except:\n",
    "                if smiles == \"###\":\n",
    "                    col.append(\"###\")\n",
    "                else:\n",
    "                    mol = Chem.MolFromSmiles(smiles)\n",
    "                    col.append(rdMolDescriptors.CalcTPSA(mol))\n",
    "            if \"###\" in col:\n",
    "                print(test_num, val.iloc[i,0])\n",
    "            tsv.append(col)\n",
    "        else:\n",
    "            col = []\n",
    "            col.append(val.iloc[i,0])\n",
    "            col.append(val.iloc[i,1])\n",
    "            for n in range(2, len(all_data_dict[val.iloc[i,0]])):\n",
    "                col.append(all_data_dict[val.iloc[i,0]][n])\n",
    "            tsv.append(col)\n",
    "    pd.DataFrame(tsv).to_csv(f\"../../data/processed/{test_num}/validation_pubchem.tsv\", sep=\"\\t\", header=None, index=False)\n",
    "\n",
    "    if len(tsv) != len(val):\n",
    "        cas = [row[0] for row in tsv]\n",
    "        print(set(val[0]) - set(cas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 485.67it/s]\n",
      "100%|██████████| 42/42 [00:00<00:00, 373.11it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 6279.27it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 278.46it/s]\n",
      "100%|██████████| 86/86 [00:00<00:00, 716.45it/s]\n",
      "100%|██████████| 86/86 [00:00<00:00, 266.52it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 14254.80it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 5425.01it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 17161.64it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 11122.52it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 18468.97it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 11087.24it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 17650.09it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 10045.14it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 25575.02it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 12106.71it/s]\n"
     ]
    }
   ],
   "source": [
    "for test_num in [\"0901\", \"0902\", \"0904\", \"0905\"]:\n",
    "    for lig in [\"ago\", \"anta\"]:\n",
    "        val = pd.read_csv(f\"../../data/processed/{test_num}_{lig}/validation_pubchem.tsv\", sep=\"\\t\", header=None)\n",
    "        lookup = for_lookup_val(val)\n",
    "        pickle_dump(lookup, f\"../../data/processed/{test_num}_{lig}/validation_lookup.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:00<00:00, 379.49it/s]\n",
      "100%|██████████| 72/72 [00:00<00:00, 248.21it/s]\n",
      "100%|██████████| 56/56 [00:00<00:00, 6357.41it/s]\n",
      "100%|██████████| 56/56 [00:00<00:00, 299.79it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 12365.56it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 4191.56it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 19614.83it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 3189.32it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 9533.86it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 3614.81it/s]\n"
     ]
    }
   ],
   "source": [
    "for test_num in [\"0701\", \"0702\", \"0907\", \"1001\", \"1002\"]:\n",
    "    val = pd.read_csv(f\"../../data/processed/{test_num}/validation_pubchem.tsv\", sep=\"\\t\", header=None)\n",
    "    lookup = for_lookup_val(val)\n",
    "    pickle_dump(lookup, f\"../../data/processed/{test_num}/validation_lookup.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for dataset publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11422/11422 [00:03<00:00, 3024.87it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "df_all = pd.read_csv(\"../../data/processed/other/all_pubchem_data.tsv\", sep=\"\\t\")\n",
    "df_all = df_all.drop_duplicates(subset=[\"CAS\"])\n",
    "all_data = dict()\n",
    "\n",
    "for i in tqdm(range(len(df_all))):\n",
    "    cas = df_all[\"CAS\"][i]\n",
    "    if cas not in all_data.keys():\n",
    "        all_data[cas] = []\n",
    "        for n in range(len(df_all.iloc[i])):\n",
    "            if n == 0 or n == 1:\n",
    "                continue\n",
    "            all_data[cas].append(df_all.iloc[i,n])\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(6278), 'CC(Cl)(Cl)Cl', np.float64(0.0), np.float64(2.4)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[\"71-55-6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6737/6737 [00:01<00:00, 5178.93it/s]\n",
      "100%|██████████| 42/42 [00:00<00:00, 22161.37it/s]\n",
      "100%|██████████| 42/42 [00:00<00:00, 22186.49it/s]\n",
      "100%|██████████| 6753/6753 [00:01<00:00, 5222.59it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 265.36it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 10472.15it/s]\n",
      "100%|██████████| 6724/6724 [00:01<00:00, 3553.19it/s]\n",
      "100%|██████████| 86/86 [00:00<00:00, 22355.76it/s]\n",
      "100%|██████████| 86/86 [00:00<00:00, 22423.86it/s]\n",
      "100%|██████████| 6760/6760 [00:01<00:00, 4782.60it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 17083.08it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 8921.34it/s]\n",
      "100%|██████████| 6772/6772 [00:00<00:00, 8346.55it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 22215.59it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 21204.77it/s]\n",
      "100%|██████████| 6770/6770 [00:00<00:00, 8534.18it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 22180.35it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 21269.29it/s]\n",
      "100%|██████████| 6766/6766 [00:00<00:00, 8376.08it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 22256.32it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 21281.06it/s]\n",
      "100%|██████████| 6768/6768 [00:00<00:00, 8482.79it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 21290.88it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 20706.93it/s]\n",
      "100%|██████████| 7039/7039 [00:01<00:00, 6524.93it/s]\n",
      "100%|██████████| 72/72 [00:00<00:00, 11221.80it/s]\n",
      "100%|██████████| 72/72 [00:00<00:00, 10489.77it/s]\n",
      "100%|██████████| 7043/7043 [00:00<00:00, 7735.67it/s]\n",
      "100%|██████████| 56/56 [00:00<00:00, 811.62it/s]\n",
      "100%|██████████| 56/56 [00:00<00:00, 13246.17it/s]\n",
      "100%|██████████| 6756/6756 [00:00<00:00, 8390.23it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 18663.68it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 18492.78it/s]\n",
      "100%|██████████| 438/438 [00:00<00:00, 5055.44it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 7018.45it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 10396.24it/s]\n",
      "100%|██████████| 435/435 [00:00<00:00, 5077.45it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 14547.77it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 13601.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tasks completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for test_num in [\"0901\", \"0902\", \"0904\", \"0905\"]:\n",
    "    for lig in [\"ago\", \"anta\"]:\n",
    "        test_name = test_num + \"_\" + lig\n",
    "        cas_tox_use = pd.read_csv(f\"../../data/processed/{test_name}/cas_sev_use.tsv\", sep=\"\\t\", header=None)\n",
    "        val = pd.read_csv(f\"../../data/processed/{test_name}/validation_pubchem.tsv\", sep=\"\\t\", header=None)\n",
    "        \n",
    "        tsv = []\n",
    "        for i in tqdm(range(len(cas_tox_use))):\n",
    "            cas = cas_tox_use.iloc[i, 0]\n",
    "            sev = cas_tox_use.iloc[i, 1]\n",
    "            if cas in all_data.keys():\n",
    "                col = [cas, sev] + all_data[cas]\n",
    "            else:\n",
    "                col = [cas, \"###\", \"###\", \"###\", \"###\"]\n",
    "            tsv.append(col)\n",
    "\n",
    "        for i in tqdm(range(len(val))):\n",
    "            cas = val.iloc[i, 0]\n",
    "            sev = val.iloc[i, 1]\n",
    "            if cas in all_data.keys():\n",
    "                col = [cas, sev] + all_data[cas]\n",
    "            else:\n",
    "                col = []\n",
    "                for n in range(len(val.iloc[i])):\n",
    "                    col.append(val.iloc[i, n])\n",
    "            tsv.append(col)\n",
    "        \n",
    "        os.makedirs(f\"../../data_validation_test_and_HTS/{test_name}\", exist_ok=True)\n",
    "        \n",
    "        names = [\"CAS\", \"severity\", \"CanonicalSmiles\", \"xlogp\", \"tpsa\"]\n",
    "        pd.DataFrame(tsv, columns=names).to_csv(f\"../../data_validation_test_and_HTS/{test_name}/all_data.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "        val_tsv = []\n",
    "        for i in tqdm(range(len(val))):\n",
    "            cas = val.iloc[i, 0]\n",
    "            sev = val.iloc[i, 1]\n",
    "            if cas in all_data.keys():\n",
    "                col = [cas, sev] + all_data[cas]\n",
    "            else:\n",
    "                col = []\n",
    "                for n in range(len(val.iloc[i])):\n",
    "                    col.append(val.iloc[i, n])\n",
    "            val_tsv.append(col)\n",
    "\n",
    "        names = [\"CAS\", \"severity\", \"CanonicalSmiles\", \"xlogp\", \"tpsa\"]\n",
    "        pd.DataFrame(val_tsv, columns=names).to_csv(f\"../../data_validation_test_and_HTS/{test_name}/validation_data.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "for test_num in [\"0701\", \"0702\", \"0907\", \"1001\", \"1002\"]:\n",
    "    test_name = test_num\n",
    "    cas_tox_use = pd.read_csv(f\"../../data/processed/{test_name}/cas_sev_use.tsv\", sep=\"\\t\", header=None)\n",
    "    val = pd.read_csv(f\"../../data/processed/{test_name}/validation_pubchem.tsv\", sep=\"\\t\", header=None)\n",
    "    \n",
    "    tsv = []\n",
    "    for i in tqdm(range(len(cas_tox_use))):\n",
    "        cas = cas_tox_use.iloc[i, 0]\n",
    "        sev = cas_tox_use.iloc[i, 1]\n",
    "        if cas in all_data.keys():\n",
    "            col = [cas, sev] + all_data[cas]\n",
    "        else:\n",
    "            col = [cas, \"###\", \"###\", \"###\", \"###\"]\n",
    "        tsv.append(col)\n",
    "\n",
    "    for i in tqdm(range(len(val))):\n",
    "        cas = val.iloc[i, 0]\n",
    "        sev = val.iloc[i, 1]\n",
    "        if cas in all_data.keys():\n",
    "            col = [cas, sev] + all_data[cas]\n",
    "        else:\n",
    "            col = []\n",
    "            for n in range(len(val.iloc[i])):\n",
    "                col.append(val.iloc[i, n])\n",
    "        tsv.append(col)\n",
    "    \n",
    "    os.makedirs(f\"../../data_validation_test_and_HTS/{test_name}\", exist_ok=True)\n",
    "    \n",
    "    names = [\"CAS\", \"severity\", \"CanonicalSmiles\", \"xlogp\", \"tpsa\"]\n",
    "    pd.DataFrame(tsv, columns=names).to_csv(f\"../../data_validation_test_and_HTS/{test_name}/all_data.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "    val_tsv = []\n",
    "    for i in tqdm(range(len(val))):\n",
    "        cas = val.iloc[i, 0]\n",
    "        sev = val.iloc[i, 1]\n",
    "        if cas in all_data.keys():\n",
    "            col = [cas, sev] + all_data[cas]\n",
    "        else:\n",
    "            col = []\n",
    "            for n in range(len(val.iloc[i])):\n",
    "                col.append(val.iloc[i, n])\n",
    "        val_tsv.append(col)\n",
    "\n",
    "    names = [\"CAS\", \"severity\", \"CanonicalSmiles\", \"xlogp\", \"tpsa\"]\n",
    "    pd.DataFrame(val_tsv, columns=names).to_csv(f\"../../data_validation_test_and_HTS/{test_name}/validation_data.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"All tasks completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For your own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"path2yourfile\", sep=\"\\t\", header=None)\n",
    "df = df.dropna()\n",
    "cas = []\n",
    "for i in range(len(df)):\n",
    "    cas.append(df.iloc[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cas = list(set(cas))\n",
    "\n",
    "property = ['CanonicalSMILES', 'XLogP', 'TPSA']\n",
    "all_data = prep_pubchem_bycas(cas, property)\n",
    "\n",
    "all_data_na = all_data[0].dropna()\n",
    "all_data_na.to_csv(\"path2yourpubchemresultfile.tsv\", sep=\"\\t\", header=None, index=False)\n",
    "\n",
    "error = set(all_data[1]) | set(cas)\n",
    "pickle_dump(error, \"path2yourpubchemerrorfile.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_na = all_data_na.reset_index()\n",
    "all_data_na = all_data_na.drop(columns=[\"index\"])\n",
    "\n",
    "all_data_dict = dict()\n",
    "for i in tqdm(range(len(all_data_na))):\n",
    "    cas = all_data_na[\"CAS\"][i]\n",
    "    if cas not in all_data_dict.keys():\n",
    "        all_data_dict[cas] = []\n",
    "        for n in range(len(all_data_na.iloc[i])):\n",
    "            all_data_dict[cas].append(all_data_na.iloc[i,n])\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "df = pd.DataFrame.from_dict(all_data_dict, orient='index', columns=[\"CID\",\"CAS\",\"CanonicalSmiles\",\"xlogp\",\"tpsa\"]).reset_index().drop(columns=[\"index\"])\n",
    "df.to_csv(\"path2yourpubchemresulttsvfile.tsv\",sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_whole = for_lookup(all_data_na)\n",
    "pickle_dump(lookup_whole, \"path2yourlookupfile.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "250102_test_env",
   "language": "python",
   "name": "250102_test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
